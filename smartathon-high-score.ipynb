{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport tqdm.notebook as tq\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-21T09:11:29.480129Z","iopub.execute_input":"2023-01-21T09:11:29.480592Z","iopub.status.idle":"2023-01-21T09:11:30.347815Z","shell.execute_reply.started":"2023-01-21T09:11:29.480495Z","shell.execute_reply":"2023-01-21T09:11:30.346787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"%cd \"/kaggle/input\"\ntrain = pd.read_csv(\"../input/smartathon/dataset/train.csv\")\ntest = pd.read_csv(\"../input/smartathon/dataset/test.csv\")\nsubmission = pd.read_csv(\"../input/smartathon/dataset/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:11:32.868128Z","iopub.execute_input":"2023-01-21T09:11:32.868504Z","iopub.status.idle":"2023-01-21T09:11:32.946679Z","shell.execute_reply.started":"2023-01-21T09:11:32.868475Z","shell.execute_reply":"2023-01-21T09:11:32.945596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reduce Size by 50% to get proper bounding boxes","metadata":{}},{"cell_type":"code","source":"os.makedirs('/kaggle/working/smartathon/resize_images', exist_ok = True)\nfor i,j in enumerate(train['image_path']):\n    img = cv2.imread(\"../input/smartathon/dataset/images/\" + j, cv2.IMREAD_UNCHANGED) \n    width = 960\n    height = 540 # keep original height\n    dim = (width, height)\n    # resize image\n    resized = cv2.resize(img, dim)\n    cv2.imwrite(\"/kaggle/working/smartathon/resize_images/\" + j,resized)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:11:34.327946Z","iopub.execute_input":"2023-01-21T09:11:34.328448Z","iopub.status.idle":"2023-01-21T09:11:34.334738Z","shell.execute_reply.started":"2023-01-21T09:11:34.328404Z","shell.execute_reply":"2023-01-21T09:11:34.333559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Bounding Box images","metadata":{}},{"cell_type":"code","source":"import cv2\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None, Inverted=False):\n    # Plots one bounding box on image img\n    tl = line_thickness or 2 # line thickness\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl)\n    if label:\n        tf = tl # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 2, thickness=tf)[0]\n    if Inverted == True:\n        c1 = c2\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n    else:\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1) # filled\n        cv2.putText(\n        img,\n        label,\n        (c1[0], c1[1] - 2),\n        0,\n        tl / 2,\n        [225, 255, 255],\n        thickness=tf,\n        lineType=cv2.LINE_AA,\n        )","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:33.151360Z","iopub.execute_input":"2023-01-21T09:12:33.151736Z","iopub.status.idle":"2023-01-21T09:12:33.160846Z","shell.execute_reply.started":"2023-01-21T09:12:33.151699Z","shell.execute_reply":"2023-01-21T09:12:33.159709Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Using readlines()\n# file1 = open('../input/smartathon/dataset/train.csv', 'r')\n# Lines = file1.readlines()\n\n# count = 0\n# # Strips the newline character\n# for line in Lines:\n#     #print(line)\n#     if count == 0:\n#         count += 1\n#         continue\n# print(count)\n# file_id_path = line.split(',')[1]\n# print(file_id_path)\n# # open image in cv2\n# img = cv2.imread(\"../input/smartathon/dataset/images/\" + file_id_path)\n# #print(img)\n# h, w, c = img.shape\n# cat = line.split(',')[2]\n# xmax = int(float(line.split(',')[3])) * 2\n# xmin = int(float(line.split(',')[4])) * 2\n# ymax = int(float(line.split(',')[5])) * 2\n# ymin = int(float(line.split(',')[6])) * 2\n# # plot the box\n# plot_one_box([xmin, ymin, xmax, ymax], img, color=(0, 255, 0), label=cat, line_thickness=2)\n# # save the image\n# # you might need to create the folder \"drawn\" first!\n# cv2.imwrite(\"../working/\" + file_id_path, img)\n# print(\"Line {}: {}\".format(count, line.strip()))\n# count += 1","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:33.162612Z","iopub.execute_input":"2023-01-21T09:12:33.163385Z","iopub.status.idle":"2023-01-21T09:12:33.171512Z","shell.execute_reply.started":"2023-01-21T09:12:33.163349Z","shell.execute_reply":"2023-01-21T09:12:33.170539Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Keeping contant height and width\ntrain['height'] = 540\ntrain['width'] = 960","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:33.174624Z","iopub.execute_input":"2023-01-21T09:12:33.175045Z","iopub.status.idle":"2023-01-21T09:12:33.186252Z","shell.execute_reply.started":"2023-01-21T09:12:33.175010Z","shell.execute_reply":"2023-01-21T09:12:33.185150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fixing issues with bounding boxes to keep xmax to 960 and xmin to 540 and keeping negative values to zero","metadata":{}},{"cell_type":"code","source":"### fixing bounding box problems\n\nfor i,j in enumerate(train['xmax']):\n    ##### xmax ---> 0 <= xmax <= 960\n    if  j > 960:\n        train['xmax'].iloc[i] = 960\n    elif j < 0:\n        train['xmax'].iloc[i] = 960\n    \n    #### xmin ----> 0 <= xmin <= xmax\n    \n    if train['xmin'].iloc[i] < 0 :\n        train['xmin'].iloc[i] =0\n    elif train['xmin'].iloc[i] > train['xmax'].iloc[i]:\n        print(\"####### highlighting index xmin <= xmax ####\" + str(i))\n    \n    ######## ymax ---> 0<= yamx <= 540\n    \n    if train['ymax'].iloc[i] > 540 :\n        train['ymax'].iloc[i] =540\n    elif train['ymax'].iloc[i] < 0:\n        train['ymax'].iloc[i] = 540\n    \n    ######## ymin ---> 0<= ymin <= ymax\n    if train['ymin'].iloc[i] < 0 :\n        train['ymin'].iloc[i] =0\n    elif train['ymin'].iloc[i] > train['ymax'].iloc[i]:\n        print(\"####### highlighting index ymin <= ymax ####\" + str(i))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:33.187980Z","iopub.execute_input":"2023-01-21T09:12:33.188284Z","iopub.status.idle":"2023-01-21T09:12:36.272377Z","shell.execute_reply.started":"2023-01-21T09:12:33.188260Z","shell.execute_reply":"2023-01-21T09:12:36.271401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.rename(columns={\"xmax\":\"x_max\",\"xmin\":\"x_min\",\"ymax\":\"y_max\",\"ymin\":\"y_min\",\"class\":\"class_id\",\"name\":\"class_name\"})","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:36.273840Z","iopub.execute_input":"2023-01-21T09:12:36.274616Z","iopub.status.idle":"2023-01-21T09:12:36.283430Z","shell.execute_reply.started":"2023-01-21T09:12:36.274569Z","shell.execute_reply":"2023-01-21T09:12:36.281846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:36.285191Z","iopub.execute_input":"2023-01-21T09:12:36.285506Z","iopub.status.idle":"2023-01-21T09:12:36.298353Z","shell.execute_reply.started":"2023-01-21T09:12:36.285481Z","shell.execute_reply":"2023-01-21T09:12:36.297327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing Input data","metadata":{}},{"cell_type":"code","source":"train['x_min'] = train.apply(lambda row: (row.x_min)/row.width, axis =1)\ntrain['y_min'] = train.apply(lambda row: (row.y_min)/row.height, axis =1)\n\ntrain['x_max'] = train.apply(lambda row: (row.x_max)/row.width, axis =1)\ntrain['y_max'] = train.apply(lambda row: (row.y_max)/row.height, axis =1)\n\ntrain['x_mid'] = train.apply(lambda row: (row.x_max+row.x_min)/2, axis =1)\ntrain['y_mid'] = train.apply(lambda row: (row.y_max+row.y_min)/2, axis =1)\n\ntrain['w'] = train.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain['h'] = train.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain['area'] = train['w']*train['h']\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:36.299776Z","iopub.execute_input":"2023-01-21T09:12:36.300396Z","iopub.status.idle":"2023-01-21T09:12:39.361171Z","shell.execute_reply.started":"2023-01-21T09:12:36.300333Z","shell.execute_reply":"2023-01-21T09:12:39.360218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_ids, class_names = list(zip(*set(zip(train.class_id, train.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.362625Z","iopub.execute_input":"2023-01-21T09:12:39.363119Z","iopub.status.idle":"2023-01-21T09:12:39.377375Z","shell.execute_reply.started":"2023-01-21T09:12:39.363079Z","shell.execute_reply":"2023-01-21T09:12:39.376303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Create path for label text files\nos.makedirs('/kaggle/working/smartathon/label_text_file', exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.382284Z","iopub.execute_input":"2023-01-21T09:12:39.383412Z","iopub.status.idle":"2023-01-21T09:12:39.387746Z","shell.execute_reply.started":"2023-01-21T09:12:39.383373Z","shell.execute_reply":"2023-01-21T09:12:39.386803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified Split custom logic\n\n* First split the lowest imabalnce class into 80:20 ratio\n* Check images into training set\n* Split next highly imbalance class and repeat the process","metadata":{}},{"cell_type":"code","source":"train_idx = []\ntest_idx = []\nfor class_ in reversed(list(train.class_name.value_counts().index)):\n    print(class_)\n    df_class = train[(train.class_name == class_) \n                     & ~(train.image_path.isin(train[train.index.isin(train_idx)].image_path))\n                     & ~(train.image_path.isin(train[train.index.isin(test_idx)].image_path))]\n    \n    if df_class.shape[0] == 1:\n        # all data goes in train class\n        train_idx.extend(list(df_class.index))\n    else:\n        print(\"Inside else =\"+str(df_class.shape))\n        # identify fractaion on the fly \n        total_rows_class = train[(train.class_name == class_)].shape[0]\n        should_be = round(total_rows_class*0.8)\n        # how many more to add \n        current_train_set_img = train[(train.index.isin(train_idx)) ].image_path.values\n        already_present = train[(train.image_path.isin(current_train_set_img)) & (train.class_name == class_)].shape[0]\n        print(\"should_be\",\"already_present\")\n        print(should_be,already_present)\n        sample_to_be = should_be-already_present\n        if sample_to_be <= 0:\n            sample_to_be = 0\n        train_set_idx = list(df_class.sample(sample_to_be,random_state=42).index)\n        test_set_idx = df_class[~(df_class.image_path.isin(df_class[df_class.index.isin(train_set_idx)].image_path))].index\n#         print(len(train_set_idx),len(test_set_idx))\n#         print(len(train_idx),len(test_idx))\n        train_idx.extend(train_set_idx)\n        test_idx.extend(test_set_idx)\n#         print(len(train_idx),len(test_idx))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.389070Z","iopub.execute_input":"2023-01-21T09:12:39.390060Z","iopub.status.idle":"2023-01-21T09:12:39.544048Z","shell.execute_reply.started":"2023-01-21T09:12:39.390022Z","shell.execute_reply":"2023-01-21T09:12:39.543041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_stratified = train[train.index.isin(train_idx)]\ntest_stratified = train[train.index.isin(test_idx)]\ntrain_final = train[train.image_path.isin(train_stratified.image_path.unique())]\ntest_final = train[train.image_path.isin(test_stratified.image_path.unique())]","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.547015Z","iopub.execute_input":"2023-01-21T09:12:39.547277Z","iopub.status.idle":"2023-01-21T09:12:39.563984Z","shell.execute_reply.started":"2023-01-21T09:12:39.547252Z","shell.execute_reply":"2023-01-21T09:12:39.563108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files = train_final.copy(deep=True)\nval_files = test_final.copy(deep=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.567280Z","iopub.execute_input":"2023-01-21T09:12:39.567529Z","iopub.status.idle":"2023-01-21T09:12:39.575715Z","shell.execute_reply.started":"2023-01-21T09:12:39.567506Z","shell.execute_reply":"2023-01-21T09:12:39.574832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files['bbox']= train_files[['class_id','x_mid','y_mid','w','h']].values.tolist()\nval_files['bbox']= val_files[['class_id','x_mid','y_mid','w','h']].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.577038Z","iopub.execute_input":"2023-01-21T09:12:39.577366Z","iopub.status.idle":"2023-01-21T09:12:39.598618Z","shell.execute_reply.started":"2023-01-21T09:12:39.577332Z","shell.execute_reply":"2023-01-21T09:12:39.597613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_files.groupby(\"image_path\")['bbox'].apply(list).reset_index(name=\"bbox\")\nvalid_df = val_files.groupby(\"image_path\")['bbox'].apply(list).reset_index(name=\"bbox\")","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.602022Z","iopub.execute_input":"2023-01-21T09:12:39.602318Z","iopub.status.idle":"2023-01-21T09:12:39.746902Z","shell.execute_reply.started":"2023-01-21T09:12:39.602292Z","shell.execute_reply":"2023-01-21T09:12:39.746008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.748390Z","iopub.execute_input":"2023-01-21T09:12:39.748957Z","iopub.status.idle":"2023-01-21T09:12:39.755848Z","shell.execute_reply.started":"2023-01-21T09:12:39.748915Z","shell.execute_reply":"2023-01-21T09:12:39.754889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.757578Z","iopub.execute_input":"2023-01-21T09:12:39.758359Z","iopub.status.idle":"2023-01-21T09:12:39.767055Z","shell.execute_reply.started":"2023-01-21T09:12:39.758319Z","shell.execute_reply":"2023-01-21T09:12:39.766031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_images(df):\n    for _, row in tq.tqdm(df.iterrows(), total=len(df)):\n        yolo_data = row['bbox']\n        yolo_data = np.array(yolo_data)\n        image_id = row['image_path'].split('.')[0]\n        np.savetxt(os.path.join('yolov5/base_dir', \n                    f\"/kaggle/working/smartathon/label_text_file/{image_id}.txt\"),\n                    yolo_data, \n                    fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"]\n                    ) # fmt means format the columns","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.768825Z","iopub.execute_input":"2023-01-21T09:12:39.769659Z","iopub.status.idle":"2023-01-21T09:12:39.776627Z","shell.execute_reply.started":"2023-01-21T09:12:39.769616Z","shell.execute_reply":"2023-01-21T09:12:39.775635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_images(train_df)\nprocess_images(valid_df)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:39.778229Z","iopub.execute_input":"2023-01-21T09:12:39.778563Z","iopub.status.idle":"2023-01-21T09:12:43.600274Z","shell.execute_reply.started":"2023-01-21T09:12:39.778531Z","shell.execute_reply":"2023-01-21T09:12:43.599187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_path'] = \"/kaggle/working/smartathon/resize_images/\" + train_df['image_path']\nvalid_df['image_path'] = \"/kaggle/working/smartathon/resize_images/\" + valid_df['image_path']","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:43.601841Z","iopub.execute_input":"2023-01-21T09:12:43.602293Z","iopub.status.idle":"2023-01-21T09:12:43.610713Z","shell.execute_reply.started":"2023-01-21T09:12:43.602256Z","shell.execute_reply":"2023-01-21T09:12:43.609747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_path = train_df['image_path']\nvalidation_image_path = valid_df['image_path']","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:43.612429Z","iopub.execute_input":"2023-01-21T09:12:43.613119Z","iopub.status.idle":"2023-01-21T09:12:43.621833Z","shell.execute_reply.started":"2023-01-21T09:12:43.613080Z","shell.execute_reply":"2023-01-21T09:12:43.621016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Copying Files to create YOLOV5 folders","metadata":{}},{"cell_type":"code","source":"os.makedirs('/kaggle/working/smartathon/labels/train', exist_ok = True)\nos.makedirs('/kaggle/working/smartathon/labels/val', exist_ok = True)\nos.makedirs('/kaggle/working/smartathon/images/train', exist_ok = True)\nos.makedirs('/kaggle/working/smartathon/images/val', exist_ok = True)\nlabel_dir = '/kaggle/working/smartathon/label_text_file'\nfor file in tqdm(train_image_path):\n    shutil.copy(file, '/kaggle/working/smartathon/images/train')\n    filename = file.split('/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/smartathon/labels/train')\n    \nfor file in tqdm(validation_image_path):\n    shutil.copy(file, '/kaggle/working/smartathon/images/val')\n    filename = file.split('/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/smartathon/labels/val')","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:12:43.623307Z","iopub.execute_input":"2023-01-21T09:12:43.623966Z","iopub.status.idle":"2023-01-21T09:12:47.462468Z","shell.execute_reply.started":"2023-01-21T09:12:43.623931Z","shell.execute_reply":"2023-01-21T09:12:47.461246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## YOLOv5 Modeling\n","metadata":{}},{"cell_type":"code","source":"len(classes)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:13:00.775353Z","iopub.execute_input":"2023-01-21T09:13:00.775754Z","iopub.status.idle":"2023-01-21T09:13:00.782181Z","shell.execute_reply.started":"2023-01-21T09:13:00.775718Z","shell.execute_reply":"2023-01-21T09:13:00.781112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '/kaggle/working/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('/kaggle/working/smartathon/images/train/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('/kaggle/working/smartathon/images/val/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 11,\n    names = classes\n    )\n\nwith open(join( cwd , 'smartathon.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'smartathon.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:13:00.783644Z","iopub.execute_input":"2023-01-21T09:13:00.784289Z","iopub.status.idle":"2023-01-21T09:13:00.839764Z","shell.execute_reply.started":"2023-01-21T09:13:00.784255Z","shell.execute_reply":"2023-01-21T09:13:00.838773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/ultralytics/yolov5\n# !git clone https://github.com/ultralytics/yolov5  # clone repo\n# %cd yolov5\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5')\n# %pip install -qr requirements.txt # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:13:00.841057Z","iopub.execute_input":"2023-01-21T09:13:00.841466Z","iopub.status.idle":"2023-01-21T09:13:03.495559Z","shell.execute_reply.started":"2023-01-21T09:13:00.841432Z","shell.execute_reply":"2023-01-21T09:13:03.494543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wandb login \"31593110873a82f820efeeda6f8b0b5ec5b5d9d2\"","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:13:03.500322Z","iopub.execute_input":"2023-01-21T09:13:03.500825Z","iopub.status.idle":"2023-01-21T09:13:06.206993Z","shell.execute_reply.started":"2023-01-21T09:13:03.500797Z","shell.execute_reply":"2023-01-21T09:13:06.205786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## YOLOV5 - Changing the metrics (Look for model fitness function), we focused more on mAP@0.5 ","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/yolov5/utils/metrics.py\n\n# %load /kaggle/working/yolov5/utils/metrics.py\n# Model validation metrics\n\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom . import general\n\n\ndef fitness(x):\n    # Model fitness as a weighted combination of metrics\n    w = [0.0, 0.0, 0.9, 0.1]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]\n    return (x[:, :4] * w).sum(1)\n\n\ndef ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir='precision-recall_curve.png', names=[]):\n    \"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).\n        pred_cls:  Predicted object classes (nparray).\n        target_cls:  True object classes (nparray).\n        plot:  Plot precision-recall curve at mAP@0.5\n        save_dir:  Plot save directory\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    \"\"\"\n\n    # Sort by objectness\n    i = np.argsort(-conf)\n    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n\n    # Find unique classes\n    unique_classes = np.unique(target_cls)\n\n    # Create Precision-Recall curve and compute AP for each class\n    px, py = np.linspace(0, 1, 1000), []  # for plotting\n    pr_score = 0.1  # score to evaluate P and R https://github.com/ultralytics/yolov3/issues/898\n    s = [unique_classes.shape[0], tp.shape[1]]  # number class, number iou thresholds (i.e. 10 for mAP0.5...0.95)\n    ap, p, r = np.zeros(s), np.zeros(s), np.zeros(s)\n    for ci, c in enumerate(unique_classes):\n        i = pred_cls == c\n        n_l = (target_cls == c).sum()  # number of labels\n        n_p = i.sum()  # number of predictions\n\n        if n_p == 0 or n_l == 0:\n            continue\n        else:\n            # Accumulate FPs and TPs\n            fpc = (1 - tp[i]).cumsum(0)\n            tpc = tp[i].cumsum(0)\n\n            # Recall\n            recall = tpc / (n_l + 1e-16)  # recall curve\n            r[ci] = np.interp(-pr_score, -conf[i], recall[:, 0])  # r at pr_score, negative x, xp because xp decreases\n\n            # Precision\n            precision = tpc / (tpc + fpc)  # precision curve\n            p[ci] = np.interp(-pr_score, -conf[i], precision[:, 0])  # p at pr_score\n\n            # AP from recall-precision curve\n            for j in range(tp.shape[1]):\n                ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])\n                if plot and (j == 0):\n                    py.append(np.interp(px, mrec, mpre))  # precision at mAP@0.5\n\n    # Compute F1 score (harmonic mean of precision and recall)\n    f1 = 2 * p * r / (p + r + 1e-16)\n\n    if plot:\n        plot_pr_curve(px, py, ap, save_dir, names)\n\n    return p, r, ap, f1, unique_classes.astype('int32')\n\n\ndef compute_ap(recall, precision):\n    \"\"\" Compute the average precision, given the recall and precision curves\n    # Arguments\n        recall:    The recall curve (list)\n        precision: The precision curve (list)\n    # Returns\n        Average precision, precision curve, recall curve\n    \"\"\"\n\n    # Append sentinel values to beginning and end\n    mrec = np.concatenate(([0.], recall, [recall[-1] + 0.01]))\n    mpre = np.concatenate(([1.], precision, [0.]))\n\n    # Compute the precision envelope\n    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n\n    # Integrate area under curve\n    method = 'interp'  # methods: 'continuous', 'interp'\n    if method == 'interp':\n        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate\n    else:  # 'continuous'\n        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes\n        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n\n    return ap, mpre, mrec\n\n\nclass ConfusionMatrix:\n    # Updated version of https://github.com/kaanakan/object_detection_confusion_matrix\n    def __init__(self, nc, conf=0.25, iou_thres=0.45):\n        self.matrix = np.zeros((nc + 1, nc + 1))\n        self.nc = nc  # number of classes\n        self.conf = conf\n        self.iou_thres = iou_thres\n\n    def process_batch(self, detections, labels):\n        \"\"\"\n        Return intersection-over-union (Jaccard index) of boxes.\n        Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n        Arguments:\n            detections (Array[N, 6]), x1, y1, x2, y2, conf, class\n            labels (Array[M, 5]), class, x1, y1, x2, y2\n        Returns:\n            None, updates confusion matrix accordingly\n        \"\"\"\n        detections = detections[detections[:, 4] > self.conf]\n        gt_classes = labels[:, 0].int()\n        detection_classes = detections[:, 5].int()\n        iou = general.box_iou(labels[:, 1:], detections[:, :4])\n\n        x = torch.where(iou > self.iou_thres)\n        if x[0].shape[0]:\n            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()\n            if x[0].shape[0] > 1:\n                matches = matches[matches[:, 2].argsort()[::-1]]\n                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n                matches = matches[matches[:, 2].argsort()[::-1]]\n                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n        else:\n            matches = np.zeros((0, 3))\n\n        n = matches.shape[0] > 0\n        m0, m1, _ = matches.transpose().astype(np.int16)\n        for i, gc in enumerate(gt_classes):\n            j = m0 == i\n            if n and sum(j) == 1:\n                self.matrix[gc, detection_classes[m1[j]]] += 1  # correct\n            else:\n                self.matrix[gc, self.nc] += 1  # background FP\n\n        if n:\n            for i, dc in enumerate(detection_classes):\n                if not any(m1 == i):\n                    self.matrix[self.nc, dc] += 1  # background FN\n\n    def matrix(self):\n        return self.matrix\n\n    def plot(self, save_dir='', names=()):\n        try:\n            import seaborn as sn\n\n            array = self.matrix / (self.matrix.sum(0).reshape(1, self.nc + 1) + 1E-6)  # normalize\n            array[array < 0.005] = np.nan  # don't annotate (would appear as 0.00)\n\n            fig = plt.figure(figsize=(12, 9), tight_layout=True)\n            sn.set(font_scale=1.0 if self.nc < 50 else 0.8)  # for label size\n            labels = (0 < len(names) < 99) and len(names) == self.nc  # apply names to ticklabels\n            sn.heatmap(array, annot=self.nc < 30, annot_kws={\"size\": 8}, cmap='Blues', fmt='.2f', square=True,\n                       xticklabels=names + ['background FN'] if labels else \"auto\",\n                       yticklabels=names + ['background FP'] if labels else \"auto\").set_facecolor((1, 1, 1))\n            fig.axes[0].set_xlabel('True')\n            fig.axes[0].set_ylabel('Predicted')\n            fig.savefig(Path(save_dir) / 'confusion_matrix.png', dpi=250)\n        except Exception as e:\n            pass\n\n    def print(self):\n        for i in range(self.nc + 1):\n            print(' '.join(map(str, self.matrix[i])))\n\n\n# Plots ----------------------------------------------------------------------------------------------------------------\n\ndef plot_pr_curve(px, py, ap, save_dir='.', names=()):\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    py = np.stack(py, axis=1)\n\n    if 0 < len(names) < 21:  # show mAP in legend if < 10 classes\n        for i, y in enumerate(py.T):\n            ax.plot(px, y, linewidth=1, label=f'{names[i]} %.3f' % ap[i, 0])  # plot(recall, precision)\n    else:\n        ax.plot(px, py, linewidth=1, color='grey')  # plot(recall, precision)\n\n    ax.plot(px, py.mean(1), linewidth=3, color='blue', label='all classes %.3f mAP@0.5' % ap[:, 0].mean())\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n    fig.savefig(Path(save_dir) / 'precision_recall_curve.png', dpi=250)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:21:36.937657Z","iopub.execute_input":"2023-01-21T09:21:36.938402Z","iopub.status.idle":"2023-01-21T09:21:36.955257Z","shell.execute_reply.started":"2023-01-21T09:21:36.938361Z","shell.execute_reply":"2023-01-21T09:21:36.953932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd \"/kaggle/working/yolov5/\"\n!WANDB_MODE=\"online\" python train.py --img 650 --batch 16 --epochs 35 --data /kaggle/working/smartathon.yaml --weights yolov5x.pt --cache","metadata":{"execution":{"iopub.status.busy":"2023-01-21T09:21:52.862082Z","iopub.execute_input":"2023-01-21T09:21:52.862470Z","iopub.status.idle":"2023-01-21T13:32:16.630327Z","shell.execute_reply.started":"2023-01-21T09:21:52.862437Z","shell.execute_reply":"2023-01-21T13:32:16.627802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Output in CSV","metadata":{}},{"cell_type":"code","source":"%cd \"/kaggle/input\"\nos.makedirs('/kaggle/working/smartathon/test', exist_ok = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:34:37.066543Z","iopub.execute_input":"2023-01-21T13:34:37.066957Z","iopub.status.idle":"2023-01-21T13:34:37.082345Z","shell.execute_reply.started":"2023-01-21T13:34:37.066922Z","shell.execute_reply":"2023-01-21T13:34:37.081295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd \"/kaggle/working/yolov5/\"","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:34:38.195283Z","iopub.execute_input":"2023-01-21T13:34:38.195636Z","iopub.status.idle":"2023-01-21T13:34:38.203605Z","shell.execute_reply.started":"2023-01-21T13:34:38.195606Z","shell.execute_reply":"2023-01-21T13:34:38.202532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/yolov5\nimport torch\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/working/yolov5/runs/train/exp/weights/best.pt', force_reload=True) ","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:34:53.090656Z","iopub.execute_input":"2023-01-21T13:34:53.091039Z","iopub.status.idle":"2023-01-21T13:34:59.436270Z","shell.execute_reply.started":"2023-01-21T13:34:53.091006Z","shell.execute_reply":"2023-01-21T13:34:59.435318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/input\nfor i,j in enumerate(test['image_path']):\n    img = cv2.imread(\"../input/smartathon/dataset/images/\" + j.split(\"/\")[-1], cv2.IMREAD_UNCHANGED) \n    width = 960\n    height = 540 # keep original height\n    dim = (width, height)\n    # resize image\n    resized = cv2.resize(img, dim)\n    cv2.imwrite(\"/kaggle/working/smartathon/resize_images/\" + j.split(\"/\")[-1],resized)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['image_path'] = \"/kaggle/working/smartathon/resize_images/\" + test['image_path']","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:35:18.713916Z","iopub.execute_input":"2023-01-21T13:35:18.714278Z","iopub.status.idle":"2023-01-21T13:35:18.727811Z","shell.execute_reply.started":"2023-01-21T13:35:18.714243Z","shell.execute_reply":"2023-01-21T13:35:18.726793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd \"/kaggle/working\"\nfinal_output = pd.DataFrame(columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"confidence\", \"class\", \"name\", \"image_path\"])\nfor i,j in enumerate(test['image_path']):\n    results = model(j,size=672,augment=True)\n    output = results.pandas().xyxy[0]\n    output['image_path'] = j.split(\"/\")[-1]\n    output = output[output['confidence'] >= 0.4]\n    if output.shape[0] == 0:\n        output = output.append(pd.DataFrame([[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,j.split(\"/\")[-1]]],columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"confidence\", \"class\", \"name\", \"image_path\"]),ignore_index=True)\n    final_output = final_output.append(output)","metadata":{"execution":{"iopub.status.busy":"2023-01-21T14:08:54.905186Z","iopub.execute_input":"2023-01-21T14:08:54.905577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_output = final_output.sort_values(['image_path','confidence'],ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### change columnsput format\nfinal_output = final_output.reset_index(drop=True)\nfinal_output = final_output[[\"class\",\"image_path\",\"name\",\"xmax\",\"xmin\",\"ymax\",\"ymin\",\"confidence\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_output.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_output.to_csv(\"augment_inf_V1_0.4.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd \"/kaggle/working\"\n# # Image\n# img = test['image_path'].iloc[7]\n\n# # Inference\n# results = model(img)\n\n# results.pandas().xyxy[0].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Zip weights for further use\n%cd /kaggle/working\n!tar -zcvf str_split_weights.tar.gz /kaggle/working/yolov5/runs/train/exp/weights/","metadata":{"execution":{"iopub.status.busy":"2023-01-21T13:41:47.418162Z","iopub.execute_input":"2023-01-21T13:41:47.418574Z","iopub.status.idle":"2023-01-21T13:42:05.026417Z","shell.execute_reply.started":"2023-01-21T13:41:47.418538Z","shell.execute_reply":"2023-01-21T13:42:05.025011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}